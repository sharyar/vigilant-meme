{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 670 X1 Mini Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Mosquito Trap Data and Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problem Statement</b>\n",
    "\n",
    "For Task 1, we were tasked in the creation of 3 regression models using Edmonton weather data and Edmonton Mosquito Trap data. These models were meant to represent a function between the number of observed mosquitoes when considering a number of weather features.\n",
    "\n",
    "In total, 3 models were created:\n",
    "1. A linear regression model to represent the number of observed mosquitoes given a number of weather features. \n",
    "2. A linear regression model to represent the number of female mosquitoes given the same weather data.\n",
    "3. A polynomial model to model the number of female mosquitoes given the same weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to creation of a linear regression model, both data sets (Edmonton Mosquito Trap Data and Edmonton Weather Data) had to be concatenated into a singular data set for analysis. During the initial inspection of the data, the following was observed:\n",
    "1. Additional logic had to be added to resolve the 'time grid' utilized by the two sets of data. Where the Mosquito Trap Data was sampled at a frequency of one data point per week, Edmonton Weather data was sampled once every hour. \n",
    "2. Because Edmonton weather data is an instantaneous measure at the recorded time, some kind of aggregation of the weather data is desired to better match the Mosquito Trap data, such as the utilization and calculation of a moving average for certain features in the weather data set (humidity, temp, dew point, wind_dir_10s, wind_speed, health_index)\n",
    "3. Within both data sets, some features have inconsistent data and therefore was ignored from the analysis. Columns with limited or no data, such as visibility, cloud cover, humidex, windchill and solar radiation were identified as unncessary to our analysis, and was removed. Similarly, rows with missing data points were also removed from our analysis.\n",
    "4. For the Edmonton Mosquito Trap data, rows marked with UnID from the IDd column represented bad data and were removed from the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Mosquito Data Pre-processing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosquito_df = pd.read_csv('data_files/Mosquito_Trap_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosquito_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows marked as No in mosquito df for the include column\n",
    "# Remove rows marked as UnID from IDd column\n",
    "mosquito_df = mosquito_df[mosquito_df.Include != 'No']\n",
    "mosquito_df = mosquito_df[mosquito_df.IDd != 'UnID']\n",
    "\n",
    "mosquito_df.drop('Include', axis=1, inplace=True)\n",
    "mosquito_df.drop('IDd', axis=1, inplace=True)\n",
    "mosquito_df.drop('Location', axis=1, inplace=True)\n",
    "\n",
    "# One hot encode region for mosquitos\n",
    "# Remove rows with missing values\n",
    "mosquito_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Edmonton Weather Data Pre-processing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('data_files/weather_stats_edmonton.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Removal of following columns: visibility, cloud cover, humidex, windchill, solar radiation\n",
    "weather_df.drop('visibility', axis=1, inplace=True)\n",
    "weather_df.drop('cloud_cover_4', axis=1, inplace=True)\n",
    "weather_df.drop('cloud_cover_8', axis=1, inplace=True)\n",
    "weather_df.drop('cloud_cover_10', axis=1, inplace=True)\n",
    "weather_df.drop('humidex', axis=1, inplace=True)\n",
    "weather_df.drop('windchill', axis=1, inplace=True)\n",
    "weather_df.drop('solar_radiation', axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with missing values\n",
    "weather_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Moving averages for the following columns in weather: \n",
    "# humidity, temp, dew point, wind_dir_10s, wind_speed, health_index\n",
    "\n",
    "def moving_average(df, col_name, num_of_days):\n",
    "    moving_average_df = df.iloc[:,1].rolling(window=num_of_days).mean()\n",
    "    return moving_average_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Concatenation of the Two Data Sets</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Date format are different between the data sets.\n",
    "2. Parsing dates from pandas?\n",
    "4. Match Time Durations between weather and Mosquito DF - Keep only data from weather df\n",
    "\n",
    "Use date from mosquito trap as starting point for going back in history -> Build features by\n",
    "computing a moving average from various points going back in time i.e 2 days, 1 week, 2 week etc.\n",
    "\n",
    "Allows us to take into account breeding conditions leading to the number of mosquitoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model A: Number of Mosquitos vs. Weather Features (Linear Regression)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lreg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(150).copy()\n",
    "train_x = train_data.loc[:,['radio']].values\n",
    "train_y = train_data['sales'].values.reshape(len(train_x),1)\n",
    "\n",
    "plt.scatter(X_train,Y_train,label='train')\n",
    "plt.scatter(X_test,Y_test, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsk = lreg.intercept_,lreg.coef_[0]\n",
    "wsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "plt.plot(X,wsk[0]+wsk[1]*X,'r')\n",
    "plt.plot(X,w[0]+w[1]*X,'g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_sk = sklreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test , Y_test)\n",
    "plt.plot(X_test , Y_pred_sk, 'g', label='scikit-learn');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_test_sk = linreg.cost_function(Features, Y_test, wsk)\n",
    "cost_test_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train_sk = sklreg.score(X_train,Y_train)\n",
    "score_test_sk = sklreg.score(X_test,Y_test)\n",
    "score_train_sk, score_test_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model B: Number of Female Mosquitos vs. Weather Features (Linear Regression)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Advertising.csv')\n",
    "X = data.loc[:,['radio','TV']].values\n",
    "Y = data['sales'].values.reshape(len(X),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linear_regression as linreg\n",
    "%time w, h, w_h = linreg.train(X_train,Y_train, 0.00001, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklreg = linear_model.LinearRegression()\n",
    "sklreg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "sklreg.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsk = [sklreg.intercept_[0],sklreg.coef_[0][0],sklreg.coef_[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.ones(shape=(len(X_test),1))\n",
    "Features = np.append(bias, X_test, axis=1)\n",
    "Y_pred = linreg.predict(Features,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_sk = sklreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({'':['Widthout normalization','With normalization','With standarization','scikit-learn'],\n",
    "              'Train score':[score(X_train, Y_train, w),\n",
    "                             score(X_train_norm, Y_train, w_n),\n",
    "                             score(X_train_std, Y_train, w_s),\n",
    "                             sklreg.score(X_train,Y_train)],\n",
    "              'Test score':[score(X_test, Y_test, w),\n",
    "                            score(normalization(X_test), Y_test, w_n),\n",
    "                            score(standardization(X_test), Y_test, w_s),\n",
    "                            sklreg.score(X_test,Y_test)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model C: Number of Female Mosquitos vs. Weather Features (Polynomial Regression)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "sklreg_poly = linear_model.LinearRegression()\n",
    "sklreg_poly.fit(X_train_poly,Y_train)\n",
    "\n",
    "Xl = np.linspace(0, 1, 100).reshape(100,1)\n",
    "Xl_poly = poly_features.fit_transform(Xl)\n",
    "\n",
    "Y_pred = sklreg_poly.predict(Xl_poly)\n",
    "plt.scatter(X_train,Y_train)\n",
    "plt.plot(Xl,Y_pred,'r');\n",
    "\n",
    "sklreg_poly.score(X_train_poly,Y_train),sklreg_poly.score(poly_features.fit_transform(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def plot_models(X,Y,X_test, Y_test, degrees):\n",
    "    for i,degree in enumerate(degrees):\n",
    "        ax = plt.subplot(1, len(degrees), i + 1)\n",
    "        poly_features = PolynomialFeatures(degree=degree)\n",
    "        sklreg = linear_model.LinearRegression()\n",
    "        pipeline = Pipeline([(\"polynomial_features\", poly_features),\n",
    "                             (\"linear_regression\", sklreg)])\n",
    "        pipeline.fit(X,Y)\n",
    "        Y_pred = pipeline.predict(X)\n",
    "        plt.plot(X_test, pipeline.predict(X_test), label=\"Model\")\n",
    "        plt.scatter(X, Y, edgecolor='b', s=20, label=\"Samples\")\n",
    "        plt.scatter(X_test, Y_test, edgecolor='r',s=15, label=\"Test\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.title(\"Degree {}\".format(degree))\n",
    "        plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plot_models(X_train,Y_train,X_test,Y_test,[1,2,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Selection</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "data = pd.read_csv('data/Advertising.csv')\n",
    "X = data.loc[:,['radio','TV','newspaper']].values\n",
    "Y = data['sales'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_test,p_value = f_regression(X_poly,Y)\n",
    "pd.DataFrame({'feature':poly_features.get_feature_names(),\n",
    "              'F_test':F_test,'p_value':p_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "X_best = SelectKBest(f_regression,5).fit_transform(X_poly, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly.shape, X_best.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For task 2, we were tasked in the creation of a predictor using three different models/approaches, which are shown in the following order: (1) Regression, (2) Support Vector Machine and (3) Random Forest. \n",
    "\n",
    "The analyzed dataset for this task was the Ionosphere dataset, which describes radar data that is collector by a system that is located in Goose Bay Labrador. The system, consisting of a phased array of 16 high frequency antennas, targeted free electrons in the ionosphere. From these observations, a \"good\" radar return and \"bad\" radar return can be recorded, where a \"good\" return is indicative that the radar return showed evidence of some kind of structure in the ionophere and a \"bad\" return indicates that the signal passed through the ionosphere.\n",
    "\n",
    "Hence, for classification, our goal is the creation of a predictor that should perform the following classification:\n",
    "g for good and b for bad = function(ionosphere features)\n",
    "\n",
    "In our analysis of each created model, each model is conducted and analyzed using a split of training and testing data. Following the intial construction of all models, a 10-fold cross validation is performed to compare model performance betewen different models/approaches. Lastly, this information, along with the results of a t-test are used to identify the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ionosphere Data Set Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to model creation, the ionosphere data was pre-processed. Note that upon visual inspection of the data, the second column was found to have no variance (e.g. all values were the same) and therefore does not provide a significant contribution to the data. Hence, the second column was removed from the analysis.\n",
    "\n",
    "For classification, the label was changed to a binary encoding where \"g\" was mapped to a 1 value and \"b\" was mapped to a 0 value. This is necessary to construct a logistic regression model so that the regression model maps to a logical value following the performed classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1  f2       f3       f4       f5       f6       f7       f8       f9  \\\n",
       "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
       "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
       "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
       "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
       "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
       "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
       "\n",
       "         f10  ...      f26      f27      f28      f29      f30      f31  \\\n",
       "0    0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1   -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2    0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3    0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4   -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "346 -0.04622  ... -0.04202  0.83479  0.00123  1.00000  0.12815  0.86660   \n",
       "347  0.01606  ...  0.01361  0.93522  0.04925  0.93159  0.08168  0.94066   \n",
       "348  0.02446  ...  0.03193  0.92489  0.02542  0.92120  0.02242  0.92459   \n",
       "349  0.00110  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238  0.96022   \n",
       "350 -0.09139  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703  0.75747   \n",
       "\n",
       "         f32      f33      f34  label  \n",
       "0   -0.54487  0.18641 -0.45300      g  \n",
       "1   -0.06288 -0.13738 -0.02447      b  \n",
       "2   -0.24180  0.56045 -0.38238      g  \n",
       "3    1.00000 -0.32382  1.00000      b  \n",
       "4   -0.59573 -0.04608 -0.65697      g  \n",
       "..       ...      ...      ...    ...  \n",
       "346 -0.10714  0.90546 -0.04307      g  \n",
       "347 -0.00035  0.91483  0.04712      g  \n",
       "348  0.00442  0.92697 -0.00577      g  \n",
       "349 -0.03757  0.87403 -0.16243      g  \n",
       "350 -0.06678  0.85764 -0.06151      g  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naming of all columns\n",
    "colnames=['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', \n",
    "          'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "          'f30', 'f31', 'f32', 'f33', 'f34', 'label']\n",
    "\n",
    "ionosphere_df = pd.read_csv('data_files/ionosphere.data', names=colnames, header=None)\n",
    "ionosphere_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categories as 1 and 0 (g = 1, b = 0)\n",
    "ionosphere_df['label'] = ionosphere_df.label.astype('category')\n",
    "encoding = {'g': 1, 'b': 0}\n",
    "ionosphere_df.label.replace(encoding, inplace=True)\n",
    "\n",
    "# Removal of the second column (f2) as all of its values are identical and there is no variance\n",
    "ionosphere_df.drop(columns=['f2'], inplace=True)\n",
    "\n",
    "X = ionosphere_df.values[:, :-1]\n",
    "y = ionosphere_df.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Perform scaling on feature set data\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEED TO REWORD THE FOLLOWING**\n",
    "An important aspect that should be considered when we have multiple features is that not all the features contribute to the model's performance in the same way. Some features are more important than others. To determine which features are most significant, we can use the measures, F-test and p-value.\n",
    "        \n",
    "**F-test** estimates the degree of linear dependency between two random variables when comparing their variances. (See [The F-test for Linear Regression](http://facweb.cs.depaul.edu/sjost/csc423/documents/f-test-reg.htm) for an explanation how to calculate it.)\n",
    "\n",
    "**p-value** is another measure that helps us determine the significance of each feature. It is used to validate or reject the **null hypothesis**. The null hypothesis ($H_0$) assumes that there is **no relationship** between a given input feature and the output. In the context of our model, it assumes that $\\theta_i=0$ for $0 \\leq i \\le n$, where $n$ is the number of parameters. The meaning of the obtained p-values is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_test</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.605478</td>\n",
       "      <td>2.747898e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.762319</td>\n",
       "      <td>1.294785e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.619616</td>\n",
       "      <td>1.830332e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126.961973</td>\n",
       "      <td>2.514817e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.934810</td>\n",
       "      <td>5.125150e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88.829431</td>\n",
       "      <td>6.126046e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.709751</td>\n",
       "      <td>8.958033e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33.230308</td>\n",
       "      <td>1.802057e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.153808</td>\n",
       "      <td>2.380466e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.124789</td>\n",
       "      <td>1.594186e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.162092</td>\n",
       "      <td>2.654432e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.913104</td>\n",
       "      <td>6.258193e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.097289</td>\n",
       "      <td>2.033046e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.655475</td>\n",
       "      <td>9.207393e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.899602</td>\n",
       "      <td>5.223575e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.665416</td>\n",
       "      <td>1.034529e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.042790</td>\n",
       "      <td>2.535397e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.880385</td>\n",
       "      <td>2.781261e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.443373</td>\n",
       "      <td>5.059389e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17.680082</td>\n",
       "      <td>3.325217e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.792263</td>\n",
       "      <td>2.924977e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.210672</td>\n",
       "      <td>1.153457e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.013387</td>\n",
       "      <td>9.079564e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.813044</td>\n",
       "      <td>3.929379e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000829</td>\n",
       "      <td>9.770453e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.362180</td>\n",
       "      <td>3.746949e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.639170</td>\n",
       "      <td>4.245551e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23.273858</td>\n",
       "      <td>2.102964e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005422</td>\n",
       "      <td>9.413425e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>33.122984</td>\n",
       "      <td>1.895201e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.452990</td>\n",
       "      <td>5.013640e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>25.545122</td>\n",
       "      <td>6.988136e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.442961</td>\n",
       "      <td>2.304753e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        F_test       p_value\n",
       "0    96.605478  2.747898e-20\n",
       "1   128.762319  1.294785e-25\n",
       "2     5.619616  1.830332e-02\n",
       "3   126.961973  2.514817e-25\n",
       "4     7.934810  5.125150e-03\n",
       "5    88.829431  6.126046e-19\n",
       "6    15.709751  8.958033e-05\n",
       "7    33.230308  1.802057e-08\n",
       "8     5.153808  2.380466e-02\n",
       "9    10.124789  1.594186e-03\n",
       "10    9.162092  2.654432e-03\n",
       "11   11.913104  6.258193e-04\n",
       "12   14.097289  2.033046e-04\n",
       "13   15.655475  9.207393e-05\n",
       "14    7.899602  5.223575e-03\n",
       "15    2.665416  1.034529e-01\n",
       "16    5.042790  2.535397e-02\n",
       "17    4.880385  2.781261e-02\n",
       "18    0.443373  5.059389e-01\n",
       "19   17.680082  3.325217e-05\n",
       "20    4.792263  2.924977e-02\n",
       "21   15.210672  1.153457e-04\n",
       "22    0.013387  9.079564e-01\n",
       "23   12.813044  3.929379e-04\n",
       "24    0.000829  9.770453e-01\n",
       "25    4.362180  3.746949e-02\n",
       "26    0.639170  4.245551e-01\n",
       "27   23.273858  2.102964e-06\n",
       "28    0.005422  9.413425e-01\n",
       "29   33.122984  1.895201e-08\n",
       "30    0.452990  5.013640e-01\n",
       "31   25.545122  6.988136e-07\n",
       "32    1.442961  2.304753e-01"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "F_test,p_value = f_regression(X_scaled,y)\n",
    "pd.DataFrame({'F_test': F_test,'p_value':p_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "X_best = SelectKBest(f_regression).fit_transform(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((351, 33), (351, 10))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape, X_best.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(1) Logistic Regression Model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model was evaluated for both scaled and unscaled feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Initialize cross validation for k-fold = 10\n",
    "cross_validation = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = linear_model.LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80555556, 0.94285714, 1.        , 0.85714286, 0.82857143,\n",
       "       0.82857143, 0.91428571, 0.85714286, 0.8       , 0.88571429])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-scaled data\n",
    "logreg_scores = cross_val_score(logreg_model, X, y, scoring='accuracy', cv=cross_validation, n_jobs=-1)\n",
    "logreg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 1.        , 0.94285714, 0.85714286, 0.85714286,\n",
       "       0.88571429, 0.91428571, 0.91428571, 0.82857143, 0.88571429])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaled data\n",
    "logreg_scores = cross_val_score(logreg_model, X_scaled, y, scoring='accuracy', cv=cross_validation, n_jobs=-1)\n",
    "logreg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 0.94285714, 0.94285714, 0.85714286, 0.8       ,\n",
       "       0.85714286, 0.82857143, 0.97142857, 0.82857143, 0.94285714])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selection of k-best\n",
    "logreg_scores = cross_val_score(logreg_model, X_best, y, scoring='accuracy', cv=cross_validation, n_jobs=-1)\n",
    "logreg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(2) Support Vector Machine</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_soft_model = SVC(kernel='linear')\n",
    "svc_soft_model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yp_soft = svc_soft_model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Margin Model accuracy: 0.9430199430199431\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Soft Margin Model accuracy:\",accuracy_score(y,Yp_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 0.97142857, 0.94285714, 0.94285714, 0.8       ,\n",
       "       0.88571429, 0.88571429, 0.91428571, 0.8       , 0.91428571])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "svc_soft_model_scores = cross_val_score(model_soft, X_scaled, y, scoring='accuracy', cv=cross_validation, n_jobs=-1)\n",
    "svc_soft_model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(3) Random Forest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators=50, random_state=0, max_depth=12)\n",
    "random_forest_model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 0.97142857, 0.94285714, 0.94285714, 0.8       ,\n",
       "       0.88571429, 0.88571429, 0.91428571, 0.8       , 0.91428571])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "random_forest_model_scores = cross_val_score(model_soft, X_scaled, y, scoring='accuracy', cv=cross_validation, n_jobs=-1)\n",
    "random_forest_model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Performance Comparison</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test, comparison of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
